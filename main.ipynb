{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "from dataloader import *\n",
    "from train_val import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iin=random.randrange(len(train_df))\n",
    "inspect_dataset(iin,'train')\n",
    "\n",
    "print(len(train_df),len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = PersonSegmentationDataset(train_df,get_train_augs())\n",
    "validset = PersonSegmentationDataset(test_df,get_val_augs())\n",
    "print(f\"Size of Trainset : {len(trainset)}\")\n",
    "print(f\"Size of Validset : {len(validset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inn=random.randrange(len(trainset))\n",
    "check_dataloaders(index=inn,loader='trainset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validloader =  DataLoader(validset,batch_size=BATCH_SIZE,)\n",
    "\n",
    "#trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True,generator=torch.Generator(device='cuda'))\n",
    "#validloader =  DataLoader(validset,batch_size=BATCH_SIZE,generator=torch.Generator(device='cuda'))\n",
    "print(f'Total number of batches in train loader : {len(trainloader)}')\n",
    "print(f'Total number of batches in Valid loader : {len(validloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images,mask in trainloader:\n",
    "  print(f' One batch image shape {images.shape}')\n",
    "  print(f' One batch mask shape {mask.shape}')\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from segmentation_models_pytorch import Unet\n",
    "from monai.losses import DiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRSegmentationModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(DRSegmentationModel, self).__init__()\n",
    "    self.arc = Unet(encoder_name=ENCODER,\n",
    "                        encoder_weights=WEIGHTS,\n",
    "                        in_channels=3,\n",
    "                        classes=1,\n",
    "                        activation=None,\n",
    "                        )\n",
    "  def forward(self, images, masks=None):\n",
    "    logits = self.arc(images)\n",
    "    if masks!=None:\n",
    "      loss1=DiceLoss(mode='binary')(logits, masks)\n",
    "      loss2= nn.BCEWithLogitsLoss()(logits, masks)\n",
    "      return logits, loss1+loss2\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DRSegmentationModel()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR, ReduceLROnPlateau\n",
    "# from torch.cuda.amp import autocast, GradScaler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr =1e-4, weight_decay =1e-5)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=1e-3, epochs=EPOCHS, steps_per_epoch=len(trainloader)) \n",
    "# scaler=GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=np.Inf\n",
    "early_stp=0\n",
    "for i in range (EPOCHS):\n",
    "  train_loss=train_net(trainloader, model, optimizer)\n",
    "  valid_loss= eval_net(validloader, model)\n",
    "  scheduler.step()  #Lr schedulers\n",
    "  if valid_loss <best_valid_loss:\n",
    "    torch.save(model.state_dict(), 'UNet-vgg16_model_micro_adam50.pt')\n",
    "    print(\"Model saved\")\n",
    "    best_valid_loss=valid_loss\n",
    "    early_stp=0\n",
    "  else:\n",
    "    early_stp+=1\n",
    "    if early_stp>=8:\n",
    "      print(\"Eraly stopping\")\n",
    "      break\n",
    "  print(f'ECPOCH : {i+1} Training Loss : {train_loss}, Validation Loss : {valid_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/home/abir/Documents/PROJECTS/seg_folder/UNet-vgg16_model_micro_adam50.pt')) # its 80+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=random.randrange(len(validset))\n",
    "# model.load_state_dict(torch.load('/home/abir/Documents/PROJECTS/seg_folder/saved models/best_model_micro_adam.pt'))\n",
    "\n",
    "# model=model.to(DEVICE)\n",
    "for i in range(len(validset)):\n",
    "    image, mask = validset[i]\n",
    "    logits_mask = model(image.to(DEVICE).unsqueeze(0)) # (c, h, w) ---> (1, C, H,W) , 1 for batch\n",
    "    pred_mask= torch.sigmoid(logits_mask)  # as we have not used sigmoid in pred function\n",
    "    pred_mask = (pred_mask>0.5)*1.0   # convert any pixel less greater than .5 to 1\n",
    "\n",
    "    show_image(image, mask, pred_mask.detach().cpu().squeeze(0)) # detach and remove batch info added earlier  \n",
    "    pred_mask=pred_mask.detach().cpu()\n",
    "    iou=iou_(mask,pred_mask)\n",
    "    f1score=f1_score_(mask,pred_mask)\n",
    "    # pred_mask=(pred_mask>0.5).float()\n",
    "    # prd_mask=pred_mask.detach().cpu().numpy().flatten()                                            #.astype(int)\n",
    "    # msk=mask.detach().cpu().numpy().flatten()                                                      #.astype(int)\n",
    "\n",
    "    # iou=jaccard_score(y_true=msk,y_pred=prd_mask)\n",
    "    # F1_score =f1_score(y_true=msk,y_pred=prd_mask)\n",
    "\n",
    "    print(f\" IOU:{iou} || F1 score:{f1score}\")\n",
    "    # print(f\"Recall:{recall} Precision:{precision}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
